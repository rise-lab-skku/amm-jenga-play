{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color shape:  (480, 640, 3)\n",
      "depth shape:  (480, 640)\n"
     ]
    }
   ],
   "source": [
    "img_color = cv2.imread('test_imgs/color_new.png')\n",
    "img_depth = cv2.imread('test_imgs/depth_new.png', 0)\n",
    "print('color shape: ', img_color.shape)\n",
    "print('depth shape: ', img_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img_color.shape[:2] # 이미지의 높이와 너비 불러옴, 가로 [0], 세로[1]\n",
    "\n",
    "img_hsv = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV) # cvtColor 함수를 이용하여 hsv 색공간으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['green', 'pink', 'yellow', 'blue', 'violet', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED\n",
    "lower_red1 = np.array([0, 120, 50])\n",
    "upper_red1 = np.array([20, 255, 255])\n",
    "lower_red2 = np.array([160,120,50])\n",
    "upper_red2 = np.array([179,255,255])\n",
    "\n",
    "# PINK\n",
    "lower_pink1 = np.array([0, 75, 100])\n",
    "upper_pink1 = np.array([10, 120, 255])\n",
    "lower_pink2 = np.array([150,75,100])\n",
    "upper_pink2 = np.array([179,120,255])\n",
    "\n",
    "# GREEN\n",
    "lower_green = (70-20, 60, 60)\n",
    "upper_green = (70+20, 255, 255)\n",
    "\n",
    "# YELLOW\n",
    "lower_yellow = (30-10, 80, 80)\n",
    "upper_yellow = (30+10, 255, 255)\n",
    "\n",
    "# BLUE\n",
    "lower_blue = (100-10, 100, 100)\n",
    "upper_blue = (100+10, 255, 150)\n",
    "\n",
    "# VIOLET\n",
    "lower_violet = (130-20, 30, 30)\n",
    "upper_violet = (130+20, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_rgb_by_color = []\n",
    "blocks_mask_by_color = []\n",
    "for color in colors:\n",
    "    if color == 'pink' or color =='red':\n",
    "        for i in (1,2):\n",
    "            exec(f\"lower_color{i} = lower_{color}{i}\")\n",
    "            exec(f\"upper_color{i} = upper_{color}{i}\")\n",
    "\n",
    "        mask_color1 = cv2.inRange(img_hsv, lower_color1, upper_color1)\n",
    "        mask_color2 = cv2.inRange(img_hsv, lower_color2, upper_color2)\n",
    "        img_mask_color = mask_color1 + mask_color2\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        erosion_image_color = cv2.erode(img_mask_color, kernel, iterations=2)  #// make erosion image\n",
    "        img_mask_color = cv2.dilate(erosion_image_color, kernel, iterations=2)  #// make dilation image\n",
    "\n",
    "        # 바이너리 이미지를 마스크로 사용하여 원본이미지에서 범위값에 해당하는 영상부분을 획득\n",
    "        img_result_color = cv2.bitwise_and(img_color, img_color, mask = img_mask_color) \n",
    "        \n",
    "        exec(f\"img_result_{color} = img_result_color\")\n",
    "    \n",
    "    else:\n",
    "        exec(f\"lower_color = lower_{color}\")\n",
    "        exec(f\"upper_color = upper_{color}\")\n",
    "\n",
    "        img_mask_color = cv2.inRange(img_hsv, lower_color, upper_color) # 범위내의 픽셀들은 흰색, 나머지 검은색\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        erosion_image_color = cv2.erode(img_mask_color, kernel, iterations=2)  #// make erosion image\n",
    "        img_mask_color = cv2.dilate(erosion_image_color, kernel, iterations=2)  #// make dilation image\n",
    "\n",
    "        # 바이너리 이미지를 마스크로 사용하여 원본이미지에서 범위값에 해당하는 영상부분을 획득\n",
    "        img_result_color = cv2.bitwise_and(img_color, img_color, mask = img_mask_color) \n",
    "\n",
    "        exec(f\"img_result_{color} = img_result_color\")\n",
    "        \n",
    "    _, src_bin = cv2.threshold(img_mask_color, 0, 255, cv2.THRESH_OTSU)\n",
    "    each_color_filtered = cv2.bitwise_and(img_color, img_color, mask = src_bin)\n",
    "    \n",
    "    if color == 'red':\n",
    "        cv2.imshow('src_bin', src_bin)\n",
    "        cv2.imshow(f'{color}_filtered', each_color_filtered)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "    blocks_color = []\n",
    "    blocks_mask = []\n",
    "\n",
    "    for i in range(1, cnt): # 각각의 객체 정보에 들어가기 위해 반복문. 범위를 1부터 시작한 이유는 배경을 제외\n",
    "        (x, y, w, h, area) = stats[i]\n",
    "        cen_x, cen_y = map(int, centroids[i])\n",
    "        block_mask = (labels==i)*img_mask_color\n",
    "        block_color = cv2.bitwise_and(img_color, img_color, mask = block_mask)\n",
    "        \n",
    "        # 노이즈 제거\n",
    "        if area < 250:\n",
    "            continue\n",
    "        \n",
    "        if color == 'red' and i==1:\n",
    "            cv2.imshow('blk clr', block_color)\n",
    "            # cv2.imwrite('./test_imgs/red_block1_rgb.png', block_color)\n",
    "            cv2.imshow('blk msk', block_mask)\n",
    "            # cv2.imwrite('./test_imgs/red_block1_mask.png', block_mask)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        blocks_color.append(block_color)\n",
    "        blocks_mask.append(block_mask)\n",
    "        \n",
    "        \n",
    "    exec(f\"blocks_rgb_{color} = blocks_color\")\n",
    "    exec(f\"blocks_mask_{color} = blocks_mask\")\n",
    "    exec(f\"blocks_rgb_by_color.append(blocks_rgb_{color})\")\n",
    "    exec(f\"blocks_mask_by_color.append(blocks_mask_{color})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_mask = 0\n",
    "tower_color = 0\n",
    "for mask, color in zip(blocks_mask_by_color, blocks_rgb_by_color):\n",
    "    for block_m in mask:\n",
    "        tower_mask += block_m\n",
    "    \n",
    "    for block_c in color:\n",
    "        tower_color += block_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('tower mask', tower_mask)\n",
    "# cv2.imwrite('./test_imgs/tower_mask.png', tower_mask)\n",
    "cv2.imshow('tower color', tower_color)\n",
    "# cv2.imwrite('./test_imgs/tower_color.png', tower_color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blocks_rgb_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "6\n",
      "pink\n",
      "6\n",
      "yellow\n",
      "6\n",
      "blue\n",
      "6\n",
      "violet\n",
      "6\n",
      "red\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for c, b, rgb_m in zip(colors, blocks_mask_by_color, blocks_rgb_by_color):\n",
    "    print(c)\n",
    "    print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp intrinsic matrix\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "intrinsic.intrinsic_matrix = [[322.282420, 0, 320.818268],[0, 322.282420, 178.779297],[0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointcloud_from_color_depth(color_image, depth_image, intrinsic):\n",
    "    o3d_img = o3d.geometry.Image()\n",
    "    \n",
    "    if isinstance(color_image, type(o3d_img)):\n",
    "        pass\n",
    "    elif isinstance(color_image, np.ndarray):\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        color_image = o3d.geometry.Image(color_image)\n",
    "        \n",
    "    if isinstance(depth_image, type(o3d_img)):\n",
    "        pass\n",
    "    elif isinstance(depth_image, np.ndarray):\n",
    "        depth_image = o3d.geometry.Image(depth_image)\n",
    "        \n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image, depth_image)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsic)\n",
    "    \n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_depth = cv2.bitwise_and(img_depth, img_depth, mask = tower_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_pcd = get_pointcloud_from_color_depth(color_image=tower_color, depth_image=masked_depth, intrinsic=intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 34089 points.\n",
      "[[-2.34823723e-05 -1.22886669e-04  4.78431379e-04]\n",
      " [-2.19978626e-05 -1.22886669e-04  4.78431379e-04]\n",
      " [-2.05133529e-05 -1.22886669e-04  4.78431379e-04]\n",
      " ...\n",
      " [ 7.59722067e-06  2.33777307e-04  3.96078423e-04]\n",
      " [ 8.82619998e-06  2.33777307e-04  3.96078423e-04]\n",
      " [ 1.00551793e-05  2.33777307e-04  3.96078423e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(tower_pcd)\n",
    "print(np.asarray(tower_pcd.points))\n",
    "o3d.visualization.draw_geometries([tower_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_pcd_by_color = []\n",
    "all_pcd = []\n",
    "for color, block_mask in zip(colors, blocks_mask_by_color):\n",
    "    # print(color)\n",
    "    blocks_pcd = []\n",
    "    for msk in block_mask:\n",
    "        masked_block_rgb = cv2.bitwise_and(tower_color, tower_color, mask = msk)\n",
    "        masked_block_depth = cv2.bitwise_and(img_depth, img_depth, mask = msk)\n",
    "        \n",
    "        # Get Each Block's PointCloud\n",
    "        pcd = get_pointcloud_from_color_depth(color_image=masked_block_rgb, depth_image=masked_block_depth, intrinsic=intrinsic)\n",
    "        \n",
    "        # Remove Outlier Points\n",
    "        pcd, _ = pcd.remove_radius_outlier(64, 0.00001)\n",
    "        blocks_pcd.append(pcd)\n",
    "        all_pcd.append(pcd)\n",
    "        \n",
    "        if color=='red':\n",
    "            o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    exec(f\"blocks_pcd_{color} = blocks_pcd\")\n",
    "    exec(f\"blocks_pcd_by_color.append(blocks_pcd_{color})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries(all_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 32938 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_combined = o3d.geometry.PointCloud()\n",
    "for point_id in range(len(all_pcd)):\n",
    "    pcd_combined += all_pcd[point_id]\n",
    "\n",
    "print(pcd_combined)\n",
    "o3d.visualization.draw_geometries([pcd_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 12 points and 4 triangles.\n"
     ]
    }
   ],
   "source": [
    "mesh = o3d.io.read_triangle_mesh(\"mesh/jenga_tower_side.stl\")\n",
    "print(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_target = mesh.sample_points_uniformly(number_of_points=32937)\n",
    "o3d.visualization.draw_geometries([pcd_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pcd_combined\n",
    "target = pcd_target\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([source, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_temp2 = copy.deepcopy(source)\n",
    "target_temp2 = copy.deepcopy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open3d.cpu.pybind.utility.Vector3dVector"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(source_temp2.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = o3d.cpu.pybind.utility.Vector3dVector(np.array(source.points)*500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_temp2.points = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 37.5       , 110.64289561, -25.37004399])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(target.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.43144444, -48.75988296, 192.15686189])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(source_temp2.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([source_temp2, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = copy.deepcopy(source_temp2)\n",
    "    target = copy.deepcopy(pcd_target)\n",
    "    trans_init = np.asarray([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0],\n",
    "                             [0.0, 0.0, -1.0, 0.0], [0.0, 0.0, 0.0, -1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.000005.\n",
      ":: Estimate normal with search radius 0.000010.\n",
      ":: Compute FPFH feature with search radius 0.000025.\n",
      ":: Downsample with a voxel size 0.000005.\n",
      ":: Estimate normal with search radius 0.000010.\n",
      ":: Compute FPFH feature with search radius 0.000025.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.000005  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "    voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.000005,\n",
      "   we use a liberal distance threshold 0.000008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
