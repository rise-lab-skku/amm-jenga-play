{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blcok Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color shape:  (1536, 2048, 3)\n",
      "depth shape:  (1536, 2048)\n"
     ]
    }
   ],
   "source": [
    "img_color = cv2.imread('test_imgs/jenga_tower_color.png')\n",
    "img_depth = cv2.imread('test_imgs/jenga_tower_depth.png', 0)\n",
    "print('color shape: ', img_color.shape)\n",
    "print('depth shape: ', img_depth.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Blocks' Masks By Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img_color.shape[:2] # 이미지의 높이와 너비 불러옴, 가로 [0], 세로[1]\n",
    "\n",
    "img_hsv = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV) # cvtColor 함수를 이용하여 hsv 색공간으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['green', 'pink', 'yellow', 'blue', 'violet', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED\n",
    "lower_red1 = np.array([0, 130, 50])\n",
    "upper_red1 = np.array([15, 255, 255])\n",
    "lower_red2 = np.array([160,130,50])\n",
    "upper_red2 = np.array([179,255,255])\n",
    "\n",
    "# PINK\n",
    "lower_pink1 = np.array([0, 70, 80])\n",
    "upper_pink1 = np.array([10, 130, 255])\n",
    "lower_pink2 = np.array([150,70,80])\n",
    "upper_pink2 = np.array([179,130,255])\n",
    "\n",
    "# GREEN\n",
    "lower_green = (70-20, 50, 50)\n",
    "upper_green = (70+15, 255, 255)\n",
    "\n",
    "# YELLOW\n",
    "lower_yellow = (30-10, 80, 80)\n",
    "upper_yellow = (30+10, 255, 255)\n",
    "\n",
    "# BLUE\n",
    "lower_blue = (100-10, 50, 50)\n",
    "upper_blue = (100+9, 255, 255)\n",
    "\n",
    "# VIOLET\n",
    "lower_violet = (130-20, 50, 50)\n",
    "upper_violet = (130+20, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_rgb_by_color = []\n",
    "blocks_mask_by_color = []\n",
    "for color in colors:\n",
    "    if color == 'pink' or color =='red':\n",
    "        for i in (1,2):\n",
    "            exec(f\"lower_color{i} = lower_{color}{i}\")\n",
    "            exec(f\"upper_color{i} = upper_{color}{i}\")\n",
    "\n",
    "        mask_color1 = cv2.inRange(img_hsv, lower_color1, upper_color1)\n",
    "        mask_color2 = cv2.inRange(img_hsv, lower_color2, upper_color2)\n",
    "        img_mask_color = mask_color1 + mask_color2\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        erosion_image_color = cv2.erode(img_mask_color, kernel, iterations=2)  #// make erosion image\n",
    "        img_mask_color = cv2.dilate(erosion_image_color, kernel, iterations=2)  #// make dilation image\n",
    "\n",
    "        # 바이너리 이미지를 마스크로 사용하여 원본이미지에서 범위값에 해당하는 영상부분을 획득\n",
    "        img_result_color = cv2.bitwise_and(img_color, img_color, mask = img_mask_color) \n",
    "        \n",
    "        exec(f\"img_result_{color} = img_result_color\")\n",
    "    \n",
    "    else:\n",
    "        exec(f\"lower_color = lower_{color}\")\n",
    "        exec(f\"upper_color = upper_{color}\")\n",
    "\n",
    "        img_mask_color = cv2.inRange(img_hsv, lower_color, upper_color) # 범위내의 픽셀들은 흰색, 나머지 검은색\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        erosion_image_color = cv2.erode(img_mask_color, kernel, iterations=2)  #// make erosion image\n",
    "        img_mask_color = cv2.dilate(erosion_image_color, kernel, iterations=2)  #// make dilation image\n",
    "\n",
    "        # 바이너리 이미지를 마스크로 사용하여 원본이미지에서 범위값에 해당하는 영상부분을 획득\n",
    "        img_result_color = cv2.bitwise_and(img_color, img_color, mask = img_mask_color) \n",
    "\n",
    "        exec(f\"img_result_{color} = img_result_color\")\n",
    "        \n",
    "    _, src_bin = cv2.threshold(img_mask_color, 0, 255, cv2.THRESH_OTSU)\n",
    "    each_color_filtered = cv2.bitwise_and(img_color, img_color, mask = src_bin)\n",
    "    \n",
    "    if color == 'violet':\n",
    "        cv2.imshow('src_bin', src_bin)\n",
    "        cv2.imshow(f'{color}_filtered', each_color_filtered)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "    blocks_color = []\n",
    "    blocks_mask = []\n",
    "\n",
    "    for i in range(1, cnt): # 각각의 객체 정보에 들어가기 위해 반복문. 범위를 1부터 시작한 이유는 배경을 제외\n",
    "        (x, y, w, h, area) = stats[i]\n",
    "        cen_x, cen_y = map(int, centroids[i])\n",
    "        block_mask = (labels==i)*img_mask_color\n",
    "        block_color = cv2.bitwise_and(img_color, img_color, mask = block_mask)\n",
    "        \n",
    "        # 노이즈 제거\n",
    "        if area < 600:\n",
    "            continue\n",
    "        \n",
    "        if color == 'violet':\n",
    "            cv2.imshow('blk clr', block_color)\n",
    "            # cv2.imwrite('./test_imgs/red_block1_rgb.png', block_color)\n",
    "            cv2.imshow('blk msk', block_mask)\n",
    "            # cv2.imwrite('./test_imgs/red_block1_mask.png', block_mask)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        blocks_color.append(block_color)\n",
    "        blocks_mask.append(block_mask)\n",
    "        \n",
    "        \n",
    "    exec(f\"blocks_rgb_{color} = blocks_color\")\n",
    "    exec(f\"blocks_mask_{color} = blocks_mask\")\n",
    "    exec(f\"blocks_rgb_by_color.append(blocks_rgb_{color})\")\n",
    "    exec(f\"blocks_mask_by_color.append(blocks_mask_{color})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_mask = 0\n",
    "tower_color = 0\n",
    "for mask, color in zip(blocks_mask_by_color, blocks_rgb_by_color):\n",
    "    for block_m in mask:\n",
    "        tower_mask += block_m\n",
    "    \n",
    "    for block_c in color:\n",
    "        tower_color += block_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('tower mask', tower_mask)\n",
    "# cv2.imwrite('./test_imgs/tower_mask.png', tower_mask)\n",
    "cv2.imshow('tower color', tower_color)\n",
    "# cv2.imwrite('./test_imgs/tower_color.png', tower_color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "6 Blocks\n",
      "pink\n",
      "6 Blocks\n",
      "yellow\n",
      "6 Blocks\n",
      "blue\n",
      "6 Blocks\n",
      "violet\n",
      "6 Blocks\n",
      "red\n",
      "6 Blocks\n"
     ]
    }
   ],
   "source": [
    "for c, b, rgb_m in zip(colors, blocks_mask_by_color, blocks_rgb_by_color):\n",
    "    print(c)\n",
    "    print(len(b), \"Blocks\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PointCloud from RGB Image + Depth Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp intrinsic matrix\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "intrinsic.intrinsic_matrix = [[971.179, 0, 1025.07],[0, 970.984, 778.291],[0, 0, 1]]\n",
    "intrinsic.intrinsic_matrix = [[971.179, 0, 1025.07],[0, 970.984, 778.291],[0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointcloud_from_color_depth(color_image, depth_image, intrinsic):\n",
    "    o3d_img = o3d.geometry.Image()\n",
    "    \n",
    "    if isinstance(color_image, type(o3d_img)):\n",
    "        pass\n",
    "    elif isinstance(color_image, np.ndarray):\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        color_image = o3d.geometry.Image(color_image)\n",
    "        \n",
    "    if isinstance(depth_image, type(o3d_img)):\n",
    "        pass\n",
    "    elif isinstance(depth_image, np.ndarray):\n",
    "        depth_image = o3d.geometry.Image(depth_image)\n",
    "        \n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image, depth_image)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsic)\n",
    "    \n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_depth = cv2.bitwise_and(img_depth, img_depth, mask = tower_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_pcd = get_pointcloud_from_color_depth(color_image=tower_color, depth_image=masked_depth, intrinsic=intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 115893 points.\n",
      "[[1.34147933e-04 7.52568333e-06 6.82352984e-04]\n",
      " [1.34850535e-04 7.52568333e-06 6.82352984e-04]\n",
      " [1.35553138e-04 7.52568333e-06 6.82352984e-04]\n",
      " ...\n",
      " [8.46677371e-05 2.42506470e-04 4.47058817e-04]\n",
      " [8.51280630e-05 2.42506470e-04 4.47058817e-04]\n",
      " [8.55883889e-05 2.42506470e-04 4.47058817e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(tower_pcd)\n",
    "print(np.asarray(tower_pcd.points))\n",
    "o3d.visualization.draw_geometries([tower_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_pcd_by_color = []\n",
    "all_pcd = []\n",
    "for color, block_mask in zip(colors, blocks_mask_by_color):\n",
    "    # print(color)\n",
    "    blocks_pcd = []\n",
    "    for msk in block_mask:\n",
    "        masked_block_rgb = cv2.bitwise_and(tower_color, tower_color, mask = msk)\n",
    "        masked_block_depth = cv2.bitwise_and(img_depth, img_depth, mask = msk)\n",
    "        \n",
    "        # Get Each Block's PointCloud\n",
    "        pcd = get_pointcloud_from_color_depth(color_image=masked_block_rgb, depth_image=masked_block_depth, intrinsic=intrinsic)\n",
    "        \n",
    "        # Remove Outlier Points\n",
    "        pcd, _ = pcd.remove_radius_outlier(512, 0.0001)\n",
    "        blocks_pcd.append(pcd)\n",
    "        all_pcd.append(pcd)\n",
    "        \n",
    "        # if color=='green':\n",
    "        #     o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    exec(f\"blocks_pcd_{color} = blocks_pcd\")\n",
    "    exec(f\"blocks_pcd_by_color.append(blocks_pcd_{color})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blocks_pcd_by_color)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 113320 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_combined = o3d.geometry.PointCloud()\n",
    "for point_id in range(len(all_pcd)):\n",
    "    pcd_combined += all_pcd[point_id]\n",
    "\n",
    "print(pcd_combined)\n",
    "# print(len(pcd_combined.points))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 12 points and 4 triangles.\n",
      "PointCloud with 113320 points.\n"
     ]
    }
   ],
   "source": [
    "mesh_tower = o3d.io.read_triangle_mesh(\"mesh/jenga_tower_side.stl\")\n",
    "print(mesh_tower)\n",
    "\n",
    "mesh_tower.compute_vertex_normals()\n",
    "# o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "pcd_target = mesh_tower.sample_points_uniformly(number_of_points=len(pcd_combined.points))\n",
    "print(pcd_target)\n",
    "o3d.visualization.draw_geometries([pcd_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_icp(source, target):\n",
    "    source_tmp = copy.deepcopy(source)\n",
    "    target_tmp = copy.deepcopy(target)\n",
    "    \n",
    "    # make the point cloud into right position\n",
    "    trans_init = np.asarray([[0, 0, -1, 0],\n",
    "                             [0, -1, 0, 0],\n",
    "                             [-1, 0, 0, 0],\n",
    "                             [0, 0, 0, 1]])\n",
    "    \n",
    "    source_tmp.transform(trans_init)\n",
    "    \n",
    "    # resize the target pointcloud to make two pointclouds into same scale\n",
    "    resize = (np.array(target_tmp.points)[:,1].max() - np.array(target_tmp.points)[:,1].min()) / (np.array(source_tmp.points)[:,1].max() - np.array(source_tmp.points)[:,1].min())\n",
    "    \n",
    "    # move the source pcd to do icp\n",
    "    move = np.array(target_tmp.get_center() - source_tmp.get_center()*resize)\n",
    "    \n",
    "    # a = o3d.cpu.pybind.utility.Vector3dVector(np.array(target_tmp.points))\n",
    "    b = o3d.cpu.pybind.utility.Vector3dVector(np.array(source_tmp.points)*resize + move)\n",
    "    \n",
    "    # target_tmp.points = a\n",
    "    source_tmp.points = b\n",
    "    \n",
    "    o3d.visualization.draw_geometries([source_tmp, target_tmp])\n",
    "    \n",
    "    return source_tmp, target_tmp, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target, resize = prepare_icp(pcd_combined, pcd_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10\n",
    "trans_init = np.asarray([[1, 0, 0, 0],\n",
    "                         [0, 1, 0, 0],\n",
    "                         [0, 0, 1, 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=5.325891e-01, inlier_rmse=4.927920e+00, and correspondence_set size of 60353\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=9.921550e-01, inlier_rmse=1.310553e+00, and correspondence_set size of 112431\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.80823603 -0.02603788 -0.58828271 18.94908214]\n",
      " [ 0.05796727  0.99768773  0.03548219 -2.10932773]\n",
      " [ 0.58599856 -0.06277913  0.80787652  1.69153206]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=20000))\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 113320 points."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_temp = copy.deepcopy(source)\n",
    "\n",
    "source_temp.transform(reg_p2p.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.3565868079812"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(source_temp.points))[:,1].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, pcd_y in enumerate(blocks_pcd_yellow):\n",
    "    exec(f\"pcd_yellow_{idx} = pcd_y\")\n",
    "\n",
    "for idx, pcd_y in enumerate(blocks_pcd_pink):\n",
    "    exec(f\"pcd_pink_{idx} = pcd_y\")\n",
    "\n",
    "# pcd_yellow_1 = blocks_pcd_yellow[1]\n",
    "# print(pcd_yellow_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 96 points and 32 triangles.\n",
      "PointCloud with 6780 points.\n"
     ]
    }
   ],
   "source": [
    "mesh_block = o3d.io.read_triangle_mesh(\"mesh/single_block_side_z.stl\")\n",
    "print(mesh_block)\n",
    "\n",
    "mesh_block.compute_vertex_normals()\n",
    "# o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "pcd_target = mesh_block.sample_points_uniformly(number_of_points=len(pcd_yellow_1.points))\n",
    "print(pcd_target)\n",
    "o3d.visualization.draw_geometries([pcd_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target, resize = prepare_icp(pcd_yellow_1, pcd_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 105\n",
    "trans_init = np.asarray([[1, 0, 0, 0],\n",
    "                         [0, 1, 0, 0],\n",
    "                         [0, 0, 1, 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=4.056047e-01, inlier_rmse=2.549297e+00, and correspondence_set size of 2750\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=5.383481e-01, inlier_rmse=2.713453e+00, and correspondence_set size of 3650\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.94735773 -0.31919888 -0.0250083   6.18490747]\n",
      " [ 0.31235907  0.938557   -0.14677384  0.61825315]\n",
      " [ 0.07032176  0.13123576  0.98885389 -0.92020799]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=20000))\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.997922939281592"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(target.points)[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.48950919174722"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pcd_yellow_1.points)[:,1].max() * resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in blocks_mask_by_color[2]:\n",
    "    cv2.imshow('m', m)\n",
    "    # cv2.imshow(f'{color}_filtered', each_color_filtered)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.829490698143406\n",
      "56.50084041162012\n",
      "81.62043314712827\n",
      "106.25294630666482\n",
      "131.59515906063885\n",
      "157.04081889734178\n"
     ]
    }
   ],
   "source": [
    "y_list1 = []\n",
    "for i in range(6):\n",
    "    exec(f\"print(np.array(pcd_yellow_{i}.points)[:,1].max() * resize)\")\n",
    "    exec(f\"y_list1.append(pcd_yellow_{i})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_init2 = np.asarray([[0, 0, -1, 0],\n",
    "                          [0, -1, 0, 0],\n",
    "                          [-1, 0, 0, 0],\n",
    "                          [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.088182544636314\n",
      "-41.5037044133849\n",
      "-65.69857790705865\n",
      "-89.59571129954578\n",
      "-114.74975587352819\n",
      "-139.46368142116125\n"
     ]
    }
   ],
   "source": [
    "y_list2 = []\n",
    "for i in range(6):\n",
    "    exec(f\"tmp = copy.deepcopy(pcd_yellow_{i})\")\n",
    "    tmp.transform(trans_init2)\n",
    "    print(np.array(tmp.points)[:,1].max() * resize)\n",
    "    y_list2.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(y_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.098270015234572"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pcd_yellow_0.points)[:,0].std() * resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1581143023328466"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pcd_pink_0.points)[:,0].std() * resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.829490698143406"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pcd_yellow_0.points)[:,1].max() * resize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
